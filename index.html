<!DOCTYPE html>
<html>
    <head>
        <title> 爬虫.remark </title>
  <meta name="marboo-template" content="remark.md.html">
        <meta name="viewport" content="width=320, initial-scale=1.0, user-scalable=yes" charset="utf-8">
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <meta name="generator" content="Marboo 1.0: http://marboo.io" />
        <meta name="date" content="2013-03-23 13:21:17" />
  <meta name="keywords" content="Marboo" />
<style>
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif);
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body {
        font-family: 'Droid Serif';
      }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
        margin-bottom: 0;
      }
      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .large { font-size: 2em; }
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        background: #e7e8e2;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
    </style>
        <!-- <link rel="stylesheet" type="text/css" href="/.media/packages/markdown/remark.js/remark.css" /> -->
        <!-- <link rel="stylesheet" type="text/css" href="/.media/css/marboo.css" media="screen" /> -->
    </head>
    <body style="background-color:transparent">
        <!--
            # This file is created from $MARBOO_HOME/.media/starts/default.html
            # 本文件由 $MARBOO_HOME/.media/starts/default.html 复制而来
        -->
        <textarea id="source" style="display:none">class: center, middle
# 爬虫技术分享

by shiqi

4月13日



---
## 0. 为什么需要爬虫？


我们想要尽量低成本的、自动化地抓取网页上有价值的信息

而且这些信息，通常数量还很多，或者手动抓取费时麻烦

所以我们的目标是：

> 动手实现一个简易的爬虫程序  


---
## 1. 从例子开始

比如我想一口气导出《生活大爆炸》全季的下载链接，

http://www.zimuzu.tv/resource/list/11005 

手动点有点 low，可以怎么做呢？
--

#### 更 Geek 一点的做法
--

用 chrome 浏览器打开资源页面，右键"审查元素",
   
可以发现，在 html 文本中所有磁力链接的格式是相似的

``` 
<a href="magnet:XXXXXXXXXXXXXXXXX" type="magnet" target="_blank">磁力</a>
```

那我可以直接在 html 文件中把这些链接找出来


---

那么如何在搜索时准确描述，找到全部的链接呢？

一个方便的工具，是使用正则表达式.red.bold[*]


``` 
(?>=<a href=")(magnet.*)(?=" type="magnet">) 
```

这条正则表达式的讲解在下一页，不想看的可以略过


.footnote[.red.bold[*] 关于正则表达式的介绍 http://www.regexlab.com/zh/regref.htm]

---


```

               匹配引号内容
               而且以 magnet 开头
                    |
                    v  
```
```
    (?>=<a href=")(magnet.*)(?=" type="magnet") 
```
```
         ^                         ^
         |                         |
    匹配前缀 <a href="             |
                            匹配后缀 " type="magnet"

```

---

## 2. 用 Python 实现

再升级一点，写个 python 脚本

``` python
import urllib
import re
from bs4 import BeautifulSoup

url = "http://www.zimuzu.tv/resource/list/11005"
response = urllib.urlopen(url)
html = response.read()
soup = BeautifulSoup(html)

tags = soup.findAll(name = "a", attrs={'href':re.compile("^magnet:")})

for i in range(len(tags)):
    print tags["href"]

```

实际运行的时候，会发现需要进入登陆页面，才会显示资源

可以先用 python 模拟登陆，并保存 cookies，然后就能访问了。  

那如何登陆呢，也不难，需要查看网站源码

---

``` html
<script>
$("#login").click(function(){
  GLOBAL.Loading();
  $('#login').attr('disabled',true);
  var email = $("input[name=email]").val();
  var password = $("input[name=password]").val();
  var remember = ($("input[name=remember]").attr("checked") == 'checked') ? 1 : 0;
  var url_back = '';
  $.post('http://www.zimuzu.tv/User/Login/ajaxLogin',
  {account:email,password:password,remember:remember,url_back:url_back},function(R){
    GLOBAL.Loading('hide');

    ...
```
注意 `$.post` 这一行，说明我们需要先向`http://www.zimuzu.tv/User/Login/ajaxLogin`页面发送如下登陆数据

```
  { 
    account:email,
    password:password,
    remember:remember,
    url_back:url_back
  }
```


---

## 3. 完整的 Python 实现
``` python
import urllib
import urllib2
import cookielib

cookie = cookielib.CookieJar()  
opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))  

values={}
values['account'] = "XXXX"
values['password'] = "XXXX"
values['remember'] = ''
values['url_back'] = ''
postdata = urllib.urlencode(values) 
request = urllib2.Request("http://www.zimuzu.tv/User/Login/ajaxLogin", postdata)
response = opener.open(request)
print response.read()
```

如果返回

`{"status":1,"info":"\u767b\u5f55\u6210\u529f\uff01","data":{"url_back":"http:\/\/www.zimuzu.tv\/user\/user\/"}}`

就说明登陆成功了

---

接着再运行

``` python
from bs4 import BeautifulSoup
import re

url = "http://www.zimuzu.tv/resource/list/11005"
response = opener.open(url)
html = response.read()
soup = BeautifulSoup(html)

tags = soup.findAll(name = "a", attrs={'href':re.compile("^magnet:")})

for i in range(len(tags)):
    print tags["href"]
```

就可以了

---

## 4. 更多衍生内容

没有提到的内容: 1. 动态网页  2. 如何爬整站 3. 反爬虫
以及更多。。。


推荐的资料：

* [Python爬虫开发（1）](http://www.freebuf.com/news/special/96763.html)
* [Python爬虫开发（2）](http://www.freebuf.com/news/special/96821.html)</textarea>
        <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js" type="text/javascript"></script>
  <script type="text/javascript">
    var hljs = remark.highlighter.engine;
  </script>
  <script src="https://gnab.github.io/remark/downloads/remark.language.js" type="text/javascript"></script>
  <script type="text/javascript">
    var slideshow = remark.create({
          highlightStyle: 'monokai',
          highlightLanguage: 'remark'
          }) ;
  </script>
    </body>
</html>

